{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function build_train_step.<locals>.train_step at 0x7f25883193b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unexpected indent (<unknown>, line 18)\n",
      "WARNING: AutoGraph could not transform <function build_train_step.<locals>.train_step at 0x7f25883193b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unexpected indent (<unknown>, line 18)\n",
      "[199999/200000]  d_loss: 0.1899, g_loss: 4.804, e_loss: 13.1178"
     ]
    }
   ],
   "source": [
    "# Code source: https://github.com/jason71995/bigan/blob/master/train_cifar10.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Concatenate,Flatten,Reshape,Conv2D,Conv2DTranspose,LeakyReLU,Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def build_generator(image_size, latent_code_length):\n",
    "    x = Input(latent_code_length)\n",
    "    y = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(512, (3, 3), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(256, (3, 3), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(128, (3, 3), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2DTranspose(image_size[-1],(3,3),strides=(2,2),padding=\"same\")(y)\n",
    "    return Model(x, y)\n",
    "\n",
    "def build_encoder(image_size, latent_code_length):\n",
    "    x = Input(image_size)\n",
    "    y = Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(128, (3, 3), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(256, (3, 3), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(512, (3, 3), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(latent_code_length[-1],(3,3),strides=(2,2),padding=\"same\")(y)\n",
    "    return Model(x, y)\n",
    "\n",
    "def build_discriminator(image_size, latent_code_length):\n",
    "    x = Input(image_size)\n",
    "    z = Input(latent_code_length)\n",
    "    _z = Flatten()(z)\n",
    "    _z = Dense(image_size[0]*image_size[1]*image_size[2])(_z)\n",
    "    _z = Reshape(image_size)(_z)\n",
    "\n",
    "    y = Concatenate()([x,_z])\n",
    "    y = Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(128, (3, 3), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(256, (3, 3), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(512, (3, 3), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(1024, (3, 3), strides=(2, 2), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Conv2D(1024, (3, 3), padding=\"same\")(y)\n",
    "    y = LeakyReLU()(y)\n",
    "    y = Flatten()(y)\n",
    "    y = Dense(1)(y)\n",
    "    return Model([x, z], [y])\n",
    "\n",
    "def build_train_step(generator, encoder, discriminator):\n",
    "    g_optimizer = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9)\n",
    "    e_optimizer = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9)\n",
    "    d_optimizer = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(real_image, real_code):\n",
    "        tf.keras.backend.set_learning_phase(True)\n",
    "\n",
    "        fake_image = generator(real_code)\n",
    "        fake_code  = encoder(real_image)\n",
    "\n",
    "        d_inputs = [tf.concat([fake_image, real_image], axis=0),\n",
    "                    tf.concat([real_code, fake_code], axis=0)]\n",
    "        d_preds = discriminator(d_inputs)\n",
    "        pred_g, pred_e = tf.split(d_preds,num_or_size_splits=2, axis=0)\n",
    "\n",
    "        d_loss = tf.reduce_mean(tf.nn.softplus(pred_g)) + \\\n",
    "                 tf.reduce_mean(tf.nn.softplus(-pred_e))\n",
    "        g_loss = tf.reduce_mean(tf.nn.softplus(-pred_g))\n",
    "        e_loss = tf.reduce_mean(tf.nn.softplus(pred_e))\n",
    "\n",
    "        d_gradients = tf.gradients(d_loss, discriminator.trainable_variables)\n",
    "        g_gradients = tf.gradients(g_loss, generator.trainable_variables)\n",
    "        e_gradients = tf.gradients(e_loss, encoder.trainable_variables)\n",
    "\n",
    "        d_optimizer.apply_gradients(zip(d_gradients, discriminator.trainable_variables))\n",
    "        g_optimizer.apply_gradients(zip(g_gradients, generator.trainable_variables))\n",
    "        e_optimizer.apply_gradients(zip(e_gradients, encoder.trainable_variables))\n",
    "\n",
    "        return d_loss, g_loss, e_loss\n",
    "\n",
    "    return train_step\n",
    "\n",
    "def train():\n",
    "    check_point = 1000\n",
    "    iters = 200 * check_point\n",
    "    image_size = (32,32,3)\n",
    "    latent_code_length = (2,2,32)\n",
    "    batch_size = 16\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    num_of_data = x_train.shape[0]\n",
    "    x_train = np.reshape(x_train, (-1, )+image_size)\n",
    "    x_train = (x_train.astype(\"float32\") / 255) * 2 - 1 #[-1,1]\n",
    "\n",
    "    z_train = np.random.uniform(-1.0, 1.0, (num_of_data, )+latent_code_length).astype(\"float32\")\n",
    "    z_test = np.random.uniform(-1.0, 1.0, (100, )+latent_code_length).astype(\"float32\")\n",
    "\n",
    "    # ==================== save x images ====================\n",
    "    image = np.reshape(x_train[:100], (10, 10, 32, 32, 3))\n",
    "    image = np.transpose(image, (0, 2, 1, 3, 4))\n",
    "    image = np.reshape(image, (10 * 32, 10 * 32, 3))\n",
    "    image = 255 * (image + 1) / 2\n",
    "    image = np.clip(image, 0, 255)\n",
    "    image = image.astype(\"uint8\")\n",
    "    Image.fromarray(image, \"RGB\").save(\"x.png\")\n",
    "    # =======================================================\n",
    "\n",
    "    generator = build_generator(image_size, latent_code_length)\n",
    "    encoder = build_encoder(image_size, latent_code_length)\n",
    "    discriminator = build_discriminator(image_size, latent_code_length)\n",
    "    train_step = build_train_step(generator, encoder, discriminator)\n",
    "\n",
    "    for i in range(iters):\n",
    "        real_images = x_train[np.random.permutation(num_of_data)[:batch_size]]\n",
    "        real_code   = z_train[np.random.permutation(num_of_data)[:batch_size]]\n",
    "\n",
    "        d_loss, g_loss, e_loss = train_step(real_images, real_code)\n",
    "        print(\"\\r[{}/{}]  d_loss: {:.4}, g_loss: {:.4}, e_loss: {:.4}\".format(i,iters, d_loss, g_loss, e_loss),end=\"\")\n",
    "\n",
    "        if (i+1)%check_point == 0:\n",
    "\n",
    "            # save G(x) images\n",
    "            image = generator.predict(encoder.predict(x_train[:100]))\n",
    "            image = np.reshape(image, (10, 10, 32, 32, 3))\n",
    "            image = np.transpose(image, (0, 2, 1, 3, 4))\n",
    "            image = np.reshape(image, (10 * 32, 10 * 32, 3))\n",
    "            image = 255 * (image + 1) / 2\n",
    "            image = np.clip(image,0,255)\n",
    "            image = image.astype(\"uint8\")\n",
    "            Image.fromarray(image, \"RGB\").save(\"G_E_x-{}.png\".format(i//check_point))\n",
    "\n",
    "            # save G(z) images\n",
    "            image = generator.predict(z_test)\n",
    "            image = np.reshape(image, (10, 10, 32, 32, 3))\n",
    "            image = np.transpose(image, (0, 2, 1, 3, 4))\n",
    "            image = np.reshape(image, (10 * 32, 10 * 32, 3))\n",
    "            image = 255 * (image + 1) / 2\n",
    "            image = np.clip(image,0,255)\n",
    "            image = image.astype(\"uint8\")\n",
    "            Image.fromarray(image, \"RGB\").save(\"G_z-{}.png\".format(i//check_point))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = (32,32,3)\n",
    "(-1, )+image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
